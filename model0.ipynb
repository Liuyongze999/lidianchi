{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-30T15:54:30.987453Z",
     "start_time": "2023-06-30T15:54:27.115507Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "from scipy import stats\n",
    "import time\n",
    "\n",
    "from sklearn.linear_model import LinearRegression,ElasticNet## 线性回归   弹性网络回归（岭回归和lasso的结合）\n",
    "from sklearn.svm import SVR## 支持向量回归\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "import xgboost# GBDT\n",
    "import lightgbm# GBDT\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from autogluon.core.models import WeightedEnsembleModel\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-30T15:54:31.429503Z",
     "start_time": "2023-06-30T15:54:30.991434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26656 entries, 0 to 26655\n",
      "Data columns (total 87 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   序号        26656 non-null  int64  \n",
      " 1   时间        26656 non-null  object \n",
      " 2   流量1       26656 non-null  float64\n",
      " 3   流量2       26656 non-null  float64\n",
      " 4   流量3       26656 non-null  float64\n",
      " 5   流量4       26656 non-null  float64\n",
      " 6   流量5       26656 non-null  float64\n",
      " 7   流量6       26656 non-null  float64\n",
      " 8   流量7       26656 non-null  float64\n",
      " 9   流量8       26656 non-null  float64\n",
      " 10  流量9       26656 non-null  float64\n",
      " 11  流量10      26656 non-null  float64\n",
      " 12  流量11      26656 non-null  float64\n",
      " 13  流量12      26656 non-null  float64\n",
      " 14  流量13      26656 non-null  float64\n",
      " 15  流量14      26656 non-null  float64\n",
      " 16  流量15      26656 non-null  float64\n",
      " 17  流量16      26656 non-null  float64\n",
      " 18  流量17      26656 non-null  float64\n",
      " 19  上部温度设定1   26656 non-null  int64  \n",
      " 20  上部温度设定2   26656 non-null  int64  \n",
      " 21  上部温度设定3   26656 non-null  int64  \n",
      " 22  上部温度设定4   26656 non-null  int64  \n",
      " 23  上部温度设定5   26656 non-null  int64  \n",
      " 24  上部温度设定6   26656 non-null  int64  \n",
      " 25  上部温度设定7   26656 non-null  int64  \n",
      " 26  上部温度设定8   26656 non-null  int64  \n",
      " 27  上部温度设定9   26656 non-null  int64  \n",
      " 28  上部温度设定10  26656 non-null  int64  \n",
      " 29  上部温度设定11  26656 non-null  int64  \n",
      " 30  上部温度设定12  26656 non-null  int64  \n",
      " 31  上部温度设定13  26656 non-null  int64  \n",
      " 32  上部温度设定14  26656 non-null  int64  \n",
      " 33  上部温度设定15  26656 non-null  int64  \n",
      " 34  上部温度设定16  26656 non-null  int64  \n",
      " 35  上部温度设定17  26656 non-null  int64  \n",
      " 36  下部温度设定1   26656 non-null  int64  \n",
      " 37  下部温度设定2   26656 non-null  int64  \n",
      " 38  下部温度设定3   26656 non-null  int64  \n",
      " 39  下部温度设定4   26656 non-null  int64  \n",
      " 40  下部温度设定5   26656 non-null  int64  \n",
      " 41  下部温度设定6   26656 non-null  int64  \n",
      " 42  下部温度设定7   26656 non-null  int64  \n",
      " 43  下部温度设定8   26656 non-null  int64  \n",
      " 44  下部温度设定9   26656 non-null  int64  \n",
      " 45  下部温度设定10  26656 non-null  int64  \n",
      " 46  下部温度设定11  26656 non-null  int64  \n",
      " 47  下部温度设定12  26656 non-null  int64  \n",
      " 48  下部温度设定13  26656 non-null  int64  \n",
      " 49  下部温度设定14  26656 non-null  int64  \n",
      " 50  下部温度设定15  26656 non-null  int64  \n",
      " 51  下部温度设定16  26656 non-null  int64  \n",
      " 52  下部温度设定17  26656 non-null  int64  \n",
      " 53  上部温度1     26656 non-null  int64  \n",
      " 54  上部温度2     26656 non-null  int64  \n",
      " 55  上部温度3     26656 non-null  int64  \n",
      " 56  上部温度4     26656 non-null  int64  \n",
      " 57  上部温度5     26656 non-null  int64  \n",
      " 58  上部温度6     26656 non-null  int64  \n",
      " 59  上部温度7     26656 non-null  int64  \n",
      " 60  上部温度8     26656 non-null  int64  \n",
      " 61  上部温度9     26656 non-null  int64  \n",
      " 62  上部温度10    26656 non-null  int64  \n",
      " 63  上部温度11    26656 non-null  int64  \n",
      " 64  上部温度12    26656 non-null  int64  \n",
      " 65  上部温度13    26656 non-null  int64  \n",
      " 66  上部温度14    26656 non-null  int64  \n",
      " 67  上部温度15    26656 non-null  int64  \n",
      " 68  上部温度16    26656 non-null  int64  \n",
      " 69  上部温度17    26656 non-null  int64  \n",
      " 70  下部温度1     26656 non-null  int64  \n",
      " 71  下部温度2     26656 non-null  int64  \n",
      " 72  下部温度3     26656 non-null  int64  \n",
      " 73  下部温度4     26656 non-null  int64  \n",
      " 74  下部温度5     26656 non-null  int64  \n",
      " 75  下部温度6     26656 non-null  int64  \n",
      " 76  下部温度7     26656 non-null  int64  \n",
      " 77  下部温度8     26656 non-null  int64  \n",
      " 78  下部温度9     26656 non-null  int64  \n",
      " 79  下部温度10    26656 non-null  int64  \n",
      " 80  下部温度11    26656 non-null  int64  \n",
      " 81  下部温度12    26656 non-null  int64  \n",
      " 82  下部温度13    26656 non-null  int64  \n",
      " 83  下部温度14    26656 non-null  int64  \n",
      " 84  下部温度15    26656 non-null  int64  \n",
      " 85  下部温度16    26656 non-null  int64  \n",
      " 86  下部温度17    26656 non-null  int64  \n",
      "dtypes: float64(17), int64(69), object(1)\n",
      "memory usage: 17.7+ MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_path = '../data/data_Preliminary_round/'\n",
    "traindata = pd.read_csv(data_path + 'train.csv')\n",
    "testdata = pd.read_csv(data_path + 'test.csv')\n",
    "submit = pd.read_csv('../data/data_Preliminary_round/提交示例.csv')\n",
    "\n",
    "traindata.info()\n",
    "## 我要将label值设置为float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-30T15:54:31.444437Z",
     "start_time": "2023-06-30T15:54:31.431495Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "traindata.columns = [\"Num\",\"Time\"]\\\n",
    "+[\"V\"+str(i) for i in range(1,18)]\\\n",
    "+[\"TSU\"+str(i) for i in range(1,18)]\\\n",
    "+[\"TSD\"+str(i) for i in range(1,18)]\\\n",
    "+[\"TU\"+str(i) for i in range(1,18)]\\\n",
    "+[\"TD\"+str(i) for i in range(1,18)]\n",
    "\n",
    "testdata.columns = [\"Num\",\"Time\"]\\\n",
    "+[\"V\"+str(i) for i in range(1,18)]\\\n",
    "+[\"TSU\"+str(i) for i in range(1,18)]\\\n",
    "+[\"TSD\"+str(i) for i in range(1,18)]\n",
    "\n",
    "submit.columns = [\"Num\"]\\\n",
    "+[\"TU\"+str(i) for i in range(1,18)]\\\n",
    "+[\"TD\"+str(i) for i in range(1,18)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-30T15:54:31.476300Z",
     "start_time": "2023-06-30T15:54:31.447425Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "traindata.drop([\"Num\",\"Time\"],axis=1,inplace=True)\n",
    "testdata.drop([\"Num\",\"Time\"],axis=1,inplace=True)\n",
    "\n",
    "label = [\"TU\"+str(i) for i in range(1,18)]\\\n",
    "+[\"TD\"+str(i) for i in range(1,18)]\n",
    "\n",
    "features = [\"V\"+str(i) for i in range(1,18)]\\\n",
    "+[\"TSU\"+str(i) for i in range(1,18)]\\\n",
    "+[\"TSD\"+str(i) for i in range(1,18)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-30T15:54:31.492227Z",
     "start_time": "2023-06-30T15:54:31.478287Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 尝试一下  不想修改 这边的值类型\n",
    "# traindata[label] = traindata[label].astype(float)\n",
    "# traindata.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-30T15:54:27.120Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]No path specified. Models will be saved in: \"AutogluonModels\\ag-20230701_042234\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230701_042234\\\"\n",
      "AutoGluon Version:  0.8.0\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19041\n",
      "Disk Space Avail:   195.82 GB / 462.26 GB (42.4%)\n",
      "Train Data Rows:    26656\n",
      "Train Data Columns: 51\n",
      "Label Column: TU1\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    10369.67 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.27s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.77s of the 299.72s of remaining time.\n",
      "\t-7.7499\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.33s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 196.95s of the 296.9s of remaining time.\n",
      "\t-7.5306\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t1.4s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 195.38s of the 295.33s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-7.1832\t = Validation score   (-mean_absolute_error)\n",
      "\t127.16s\t = Training   runtime\n",
      "\t130.33s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 37.17s of the 137.12s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-6.8073\t = Validation score   (-mean_absolute_error)\n",
      "\t33.34s\t = Training   runtime\n",
      "\t28.09s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.73s of the 94.91s of remaining time.\n",
      "\t-6.6463\t = Validation score   (-mean_absolute_error)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 94.48s of the 94.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-6.1057\t = Validation score   (-mean_absolute_error)\n",
      "\t41.93s\t = Training   runtime\n",
      "\t6.48s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 44.95s of the 44.94s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-6.2156\t = Validation score   (-mean_absolute_error)\n",
      "\t8.19s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 31.33s of the 31.32s of remaining time.\n",
      "\t-5.8756\t = Validation score   (-mean_absolute_error)\n",
      "\t63.43s\t = Training   runtime\n",
      "\t1.49s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.73s of the -34.21s of remaining time.\n",
      "\t-5.8645\t = Validation score   (-mean_absolute_error)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 334.6s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230701_042234\\\")\n",
      "  3%|▎         | 1/34 [06:08<3:22:53, 368.91s/it]No path specified. Models will be saved in: \"AutogluonModels\\ag-20230701_042843\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230701_042843\\\"\n",
      "AutoGluon Version:  0.8.0\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19041\n",
      "Disk Space Avail:   195.05 GB / 462.26 GB (42.2%)\n",
      "Train Data Rows:    26656\n",
      "Train Data Columns: 51\n",
      "Label Column: TU2\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    10005.86 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.24s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.79s of the 299.76s of remaining time.\n",
      "\t-6.9573\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.44s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 198.22s of the 298.19s of remaining time.\n",
      "\t-6.7655\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t1.42s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 196.64s of the 296.61s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-6.4729\t = Validation score   (-mean_absolute_error)\n",
      "\t126.02s\t = Training   runtime\n",
      "\t119.89s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 47.9s of the 147.86s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-6.1062\t = Validation score   (-mean_absolute_error)\n",
      "\t40.95s\t = Training   runtime\n",
      "\t39.81s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.76s of the 94.91s of remaining time.\n",
      "\t-5.9619\t = Validation score   (-mean_absolute_error)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 94.5s of the 94.48s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-5.5386\t = Validation score   (-mean_absolute_error)\n",
      "\t30.68s\t = Training   runtime\n",
      "\t5.6s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 57.1s of the 57.08s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-5.5943\t = Validation score   (-mean_absolute_error)\n",
      "\t6.64s\t = Training   runtime\n",
      "\t0.41s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 45.14s of the 45.12s of remaining time.\n",
      "\t-5.289\t = Validation score   (-mean_absolute_error)\n",
      "\t62.52s\t = Training   runtime\n",
      "\t1.53s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.76s of the -19.42s of remaining time.\n",
      "\t-5.2838\t = Validation score   (-mean_absolute_error)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 319.76s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230701_042843\\\")\n",
      "  6%|▌         | 2/34 [12:03<3:12:14, 360.45s/it]No path specified. Models will be saved in: \"AutogluonModels\\ag-20230701_043438\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230701_043438\\\"\n",
      "AutoGluon Version:  0.8.0\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19041\n",
      "Disk Space Avail:   194.26 GB / 462.26 GB (42.0%)\n",
      "Train Data Rows:    26656\n",
      "Train Data Columns: 51\n",
      "Label Column: TU3\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9785.16 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.23s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.79s of the 299.76s of remaining time.\n",
      "\t-4.9919\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.38s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 198.19s of the 298.16s of remaining time.\n",
      "\t-4.8546\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.39s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 196.64s of the 296.61s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-4.6706\t = Validation score   (-mean_absolute_error)\n",
      "\t128.34s\t = Training   runtime\n",
      "\t131.48s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 42.81s of the 142.78s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-4.409\t = Validation score   (-mean_absolute_error)\n",
      "\t38.26s\t = Training   runtime\n",
      "\t31.0s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.77s of the 94.54s of remaining time.\n",
      "\t-4.2904\t = Validation score   (-mean_absolute_error)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 94.13s of the 94.12s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-3.9736\t = Validation score   (-mean_absolute_error)\n",
      "\t25.5s\t = Training   runtime\n",
      "\t4.24s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 61.76s of the 61.74s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-3.9879\t = Validation score   (-mean_absolute_error)\n",
      "\t7.03s\t = Training   runtime\n",
      "\t0.45s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 48.39s of the 48.37s of remaining time.\n",
      "\t-3.7794\t = Validation score   (-mean_absolute_error)\n",
      "\t67.22s\t = Training   runtime\n",
      "\t1.5s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.77s of the -21.12s of remaining time.\n",
      "\t-3.771\t = Validation score   (-mean_absolute_error)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 321.43s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230701_043438\\\")\n",
      "  9%|▉         | 3/34 [18:01<3:05:34, 359.17s/it]No path specified. Models will be saved in: \"AutogluonModels\\ag-20230701_044035\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230701_044035\\\"\n",
      "AutoGluon Version:  0.8.0\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19041\n",
      "Disk Space Avail:   193.53 GB / 462.26 GB (41.9%)\n",
      "Train Data Rows:    26656\n",
      "Train Data Columns: 51\n",
      "Label Column: TU4\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9702.79 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.24s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.79s of the 299.75s of remaining time.\n",
      "\t-2.9913\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.5s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 198.17s of the 298.14s of remaining time.\n",
      "\t-2.9163\t = Validation score   (-mean_absolute_error)\n",
      "\t0.06s\t = Training   runtime\n",
      "\t1.51s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 196.5s of the 296.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-2.8294\t = Validation score   (-mean_absolute_error)\n",
      "\t126.05s\t = Training   runtime\n",
      "\t125.23s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 45.62s of the 145.59s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-2.6266\t = Validation score   (-mean_absolute_error)\n",
      "\t40.17s\t = Training   runtime\n",
      "\t25.65s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.76s of the 96.06s of remaining time.\n",
      "\t-2.5732\t = Validation score   (-mean_absolute_error)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 95.64s of the 95.63s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-2.3632\t = Validation score   (-mean_absolute_error)\n",
      "\t22.7s\t = Training   runtime\n",
      "\t4.31s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 66.13s of the 66.12s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-2.3398\t = Validation score   (-mean_absolute_error)\n",
      "\t5.62s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 54.92s of the 54.9s of remaining time.\n",
      "\t-2.2612\t = Validation score   (-mean_absolute_error)\n",
      "\t73.74s\t = Training   runtime\n",
      "\t1.55s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.76s of the -20.85s of remaining time.\n",
      "\t-2.2452\t = Validation score   (-mean_absolute_error)\n",
      "\t0.29s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 321.18s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230701_044035\\\")\n",
      " 12%|█▏        | 4/34 [23:55<2:58:42, 357.41s/it]No path specified. Models will be saved in: \"AutogluonModels\\ag-20230701_044630\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230701_044630\\\"\n",
      "AutoGluon Version:  0.8.0\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19041\n",
      "Disk Space Avail:   192.87 GB / 462.26 GB (41.7%)\n",
      "Train Data Rows:    26656\n",
      "Train Data Columns: 51\n",
      "Label Column: TU5\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9700.93 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.23s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.79s of the 299.76s of remaining time.\n",
      "\t-3.4277\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.53s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 198.13s of the 298.1s of remaining time.\n",
      "\t-3.3569\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t1.5s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 196.48s of the 296.45s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-3.2249\t = Validation score   (-mean_absolute_error)\n",
      "\t135.66s\t = Training   runtime\n",
      "\t112.88s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 41.26s of the 141.22s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-3.0927\t = Validation score   (-mean_absolute_error)\n",
      "\t36.79s\t = Training   runtime\n",
      "\t25.6s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.77s of the 95.42s of remaining time.\n",
      "\t-3.0023\t = Validation score   (-mean_absolute_error)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 95.04s of the 95.03s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-2.9007\t = Validation score   (-mean_absolute_error)\n",
      "\t32.89s\t = Training   runtime\n",
      "\t5.03s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 54.87s of the 54.86s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-2.9252\t = Validation score   (-mean_absolute_error)\n",
      "\t6.9s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 42.16s of the 42.15s of remaining time.\n",
      "\t-2.7882\t = Validation score   (-mean_absolute_error)\n",
      "\t73.05s\t = Training   runtime\n",
      "\t1.47s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.77s of the -32.91s of remaining time.\n",
      "\t-2.7715\t = Validation score   (-mean_absolute_error)\n",
      "\t0.29s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 333.24s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230701_044630\\\")\n",
      " 15%|█▍        | 5/34 [30:04<2:54:45, 361.58s/it]No path specified. Models will be saved in: \"AutogluonModels\\ag-20230701_045239\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230701_045239\\\"\n",
      "AutoGluon Version:  0.8.0\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19041\n",
      "Disk Space Avail:   192.17 GB / 462.26 GB (41.6%)\n",
      "Train Data Rows:    26656\n",
      "Train Data Columns: 51\n",
      "Label Column: TU6\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9634.77 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.24s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.79s of the 299.76s of remaining time.\n",
      "\t-2.8262\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.59s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 198.04s of the 298.01s of remaining time.\n",
      "\t-2.7918\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t1.63s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 196.24s of the 296.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-2.6655\t = Validation score   (-mean_absolute_error)\n",
      "\t139.49s\t = Training   runtime\n",
      "\t98.65s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 36.09s of the 136.06s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-2.5953\t = Validation score   (-mean_absolute_error)\n",
      "\t32.58s\t = Training   runtime\n",
      "\t9.07s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.76s of the 96.23s of remaining time.\n",
      "\t-2.5156\t = Validation score   (-mean_absolute_error)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 95.86s of the 95.85s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-2.4912\t = Validation score   (-mean_absolute_error)\n",
      "\t17.9s\t = Training   runtime\n",
      "\t2.04s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 71.12s of the 71.11s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-2.4879\t = Validation score   (-mean_absolute_error)\n",
      "\t7.29s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 57.53s of the 57.52s of remaining time.\n",
      "\t-2.4136\t = Validation score   (-mean_absolute_error)\n",
      "\t83.74s\t = Training   runtime\n",
      "\t1.5s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.76s of the -28.2s of remaining time.\n",
      "\t-2.3958\t = Validation score   (-mean_absolute_error)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 328.52s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230701_045239\\\")\n",
      " 18%|█▊        | 6/34 [36:04<2:48:22, 360.80s/it]No path specified. Models will be saved in: \"AutogluonModels\\ag-20230701_045838\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230701_045838\\\"\n",
      "AutoGluon Version:  0.8.0\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19041\n",
      "Disk Space Avail:   191.57 GB / 462.26 GB (41.4%)\n",
      "Train Data Rows:    26656\n",
      "Train Data Columns: 51\n",
      "Label Column: TU7\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9591.98 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.24s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.79s of the 299.76s of remaining time.\n",
      "\t-1.7016\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.65s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 197.99s of the 297.96s of remaining time.\n",
      "\t-1.6743\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t1.65s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 196.16s of the 296.12s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-1.6604\t = Validation score   (-mean_absolute_error)\n",
      "\t138.27s\t = Training   runtime\n",
      "\t102.83s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 36.81s of the 136.77s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-1.6039\t = Validation score   (-mean_absolute_error)\n",
      "\t31.46s\t = Training   runtime\n",
      "\t13.2s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.76s of the 96.71s of remaining time.\n",
      "\t-1.5439\t = Validation score   (-mean_absolute_error)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 96.28s of the 96.27s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-1.5421\t = Validation score   (-mean_absolute_error)\n",
      "\t39.29s\t = Training   runtime\n",
      "\t7.81s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 49.4s of the 49.39s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-1.5517\t = Validation score   (-mean_absolute_error)\n",
      "\t9.31s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 33.85s of the 33.84s of remaining time.\n",
      "\t-1.464\t = Validation score   (-mean_absolute_error)\n",
      "\t61.95s\t = Training   runtime\n",
      "\t1.4s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.76s of the -30.09s of remaining time.\n",
      "\t-1.4581\t = Validation score   (-mean_absolute_error)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 330.41s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230701_045838\\\")\n",
      " 21%|██        | 7/34 [42:08<2:42:51, 361.89s/it]No path specified. Models will be saved in: \"AutogluonModels\\ag-20230701_050443\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230701_050443\\\"\n",
      "AutoGluon Version:  0.8.0\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19041\n",
      "Disk Space Avail:   190.97 GB / 462.26 GB (41.3%)\n",
      "Train Data Rows:    26656\n",
      "Train Data Columns: 51\n",
      "Label Column: TU8\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9642.65 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.24s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.79s of the 299.75s of remaining time.\n",
      "\t-0.1567\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.67s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 197.99s of the 297.95s of remaining time.\n",
      "\t-0.1467\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t1.64s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 196.17s of the 296.14s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.1941\t = Validation score   (-mean_absolute_error)\n",
      "\t130.66s\t = Training   runtime\n",
      "\t80.08s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 46.63s of the 146.6s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.1274\t = Validation score   (-mean_absolute_error)\n",
      "\t7.32s\t = Training   runtime\n",
      "\t0.42s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 33.09s of the 133.05s of remaining time.\n",
      "\t-0.1348\t = Validation score   (-mean_absolute_error)\n",
      "\t31.31s\t = Training   runtime\n",
      "\t0.95s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 0.64s of the 100.6s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping CatBoost_BAG_L1.\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.76s of the 93.47s of remaining time.\n",
      "2023-07-01 13:08:09,623\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-07-01 13:08:09,627\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-07-01 13:08:09,631\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-07-01 13:08:09,635\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-07-01 13:08:09,639\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-07-01 13:08:09,643\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-07-01 13:08:09,650\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-0.125\t = Validation score   (-mean_absolute_error)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 93.0s of the 92.99s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.1855\t = Validation score   (-mean_absolute_error)\n",
      "\t79.2s\t = Training   runtime\n",
      "\t80.22s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.76s of the -5.51s of remaining time.\n",
      "\t-0.1855\t = Validation score   (-mean_absolute_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 305.56s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230701_050443\\\")\n",
      " 24%|██▎       | 8/34 [47:40<2:32:40, 352.34s/it]No path specified. Models will be saved in: \"AutogluonModels\\ag-20230701_051014\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230701_051014\\\"\n",
      "AutoGluon Version:  0.8.0\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19041\n",
      "Disk Space Avail:   190.53 GB / 462.26 GB (41.2%)\n",
      "Train Data Rows:    26656\n",
      "Train Data Columns: 51\n",
      "Label Column: TU9\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9671.28 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.23s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.79s of the 299.76s of remaining time.\n",
      "\t-0.082\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.72s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 197.9s of the 297.87s of remaining time.\n",
      "\t-0.0711\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.68s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 196.09s of the 296.06s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.1196\t = Validation score   (-mean_absolute_error)\n",
      "\t137.86s\t = Training   runtime\n",
      "\t128.97s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 39.26s of the 139.23s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.0647\t = Validation score   (-mean_absolute_error)\n",
      "\t7.4s\t = Training   runtime\n",
      "\t0.49s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 25.68s of the 125.64s of remaining time.\n",
      "\t-0.0657\t = Validation score   (-mean_absolute_error)\n",
      "\t25.34s\t = Training   runtime\n",
      "\t0.91s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.77s of the 99.18s of remaining time.\n",
      "\t-0.0607\t = Validation score   (-mean_absolute_error)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 98.77s of the 98.76s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.119\t = Validation score   (-mean_absolute_error)\n",
      "\t85.33s\t = Training   runtime\n",
      "\t86.61s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.77s of the -6.53s of remaining time.\n",
      "\t-0.119\t = Validation score   (-mean_absolute_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 306.58s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230701_051014\\\")\n",
      " 26%|██▋       | 9/34 [53:17<2:24:51, 347.65s/it]No path specified. Models will be saved in: \"AutogluonModels\\ag-20230701_051552\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230701_051552\\\"\n",
      "AutoGluon Version:  0.8.0\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19041\n",
      "Disk Space Avail:   190.08 GB / 462.26 GB (41.1%)\n",
      "Train Data Rows:    26656\n",
      "Train Data Columns: 51\n",
      "Label Column: TU10\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9699.18 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.24s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.79s of the 299.75s of remaining time.\n",
      "\t-0.0733\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t1.7s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 197.91s of the 297.87s of remaining time.\n",
      "\t-0.0625\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t1.72s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 196.01s of the 295.97s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.1118\t = Validation score   (-mean_absolute_error)\n",
      "\t136.3s\t = Training   runtime\n",
      "\t123.87s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 37.77s of the 137.73s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.0574\t = Validation score   (-mean_absolute_error)\n",
      "\t7.28s\t = Training   runtime\n",
      "\t0.46s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 24.31s of the 124.27s of remaining time.\n",
      "\t-0.056\t = Validation score   (-mean_absolute_error)\n",
      "\t22.08s\t = Training   runtime\n",
      "\t0.85s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1.22s of the 101.18s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping CatBoost_BAG_L1.\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.76s of the 94.3s of remaining time.\n",
      "2023-07-01 13:19:18,048\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-07-01 13:19:18,053\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-07-01 13:19:18,057\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-07-01 13:19:18,062\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-07-01 13:19:18,065\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-07-01 13:19:18,070\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-07-01 13:19:18,073\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-0.0524\t = Validation score   (-mean_absolute_error)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 93.84s of the 93.83s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.1153\t = Validation score   (-mean_absolute_error)\n",
      "\t81.46s\t = Training   runtime\n",
      "\t84.64s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.76s of the -6.37s of remaining time.\n",
      "\t-0.1153\t = Validation score   (-mean_absolute_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 306.41s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230701_051552\\\")\n",
      " 29%|██▉       | 10/34 [58:54<2:17:43, 344.32s/it]No path specified. Models will be saved in: \"AutogluonModels\\ag-20230701_052129\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230701_052129\\\"\n",
      "AutoGluon Version:  0.8.0\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19041\n",
      "Disk Space Avail:   189.64 GB / 462.26 GB (41.0%)\n",
      "Train Data Rows:    26656\n",
      "Train Data Columns: 51\n",
      "Label Column: TU11\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9671.11 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.24s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.79s of the 299.76s of remaining time.\n",
      "\t-0.0859\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.69s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 197.95s of the 297.92s of remaining time.\n",
      "\t-0.0744\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.67s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 196.13s of the 296.09s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.1238\t = Validation score   (-mean_absolute_error)\n",
      "\t132.8s\t = Training   runtime\n",
      "\t130.79s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 40.55s of the 140.52s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.0771\t = Validation score   (-mean_absolute_error)\n",
      "\t7.53s\t = Training   runtime\n",
      "\t0.49s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 26.7s of the 126.66s of remaining time.\n",
      "\t-0.0684\t = Validation score   (-mean_absolute_error)\n",
      "\t22.84s\t = Training   runtime\n",
      "\t0.88s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 2.77s of the 102.74s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-26.1553\t = Validation score   (-mean_absolute_error)\n",
      "\t2.52s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.76s of the 94.41s of remaining time.\n",
      "\t-0.0655\t = Validation score   (-mean_absolute_error)\n",
      "\t0.6s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 93.78s of the 93.76s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.1274\t = Validation score   (-mean_absolute_error)\n",
      "\t81.96s\t = Training   runtime\n",
      "\t80.82s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.76s of the -6.45s of remaining time.\n",
      "\t-0.1274\t = Validation score   (-mean_absolute_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 306.5s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230701_052129\\\")\n",
      " 32%|███▏      | 11/34 [1:04:31<2:11:12, 342.29s/it]No path specified. Models will be saved in: \"AutogluonModels\\ag-20230701_052706\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230701_052706\\\"\n",
      "AutoGluon Version:  0.8.0\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19041\n",
      "Disk Space Avail:   189.20 GB / 462.26 GB (40.9%)\n",
      "Train Data Rows:    26656\n",
      "Train Data Columns: 51\n",
      "Label Column: TU12\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9704.94 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.24s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.79s of the 299.76s of remaining time.\n",
      "\t-0.1307\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t1.69s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 197.96s of the 297.93s of remaining time.\n",
      "\t-0.1186\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t1.67s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 196.09s of the 296.05s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.173\t = Validation score   (-mean_absolute_error)\n",
      "\t136.18s\t = Training   runtime\n",
      "\t119.04s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 39.25s of the 139.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.1222\t = Validation score   (-mean_absolute_error)\n",
      "\t9.0s\t = Training   runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 23.84s of the 123.8s of remaining time.\n",
      "\t-0.1118\t = Validation score   (-mean_absolute_error)\n",
      "\t25.25s\t = Training   runtime\n",
      "\t0.88s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.76s of the 97.51s of remaining time.\n",
      "\t-0.1067\t = Validation score   (-mean_absolute_error)\n",
      "\t0.38s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 97.11s of the 97.09s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.1687\t = Validation score   (-mean_absolute_error)\n",
      "\t84.09s\t = Training   runtime\n",
      "\t89.08s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.76s of the -6.56s of remaining time.\n",
      "\t-0.1687\t = Validation score   (-mean_absolute_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 306.61s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230701_052706\\\")\n",
      " 35%|███▌      | 12/34 [1:10:09<2:04:59, 340.90s/it]No path specified. Models will be saved in: \"AutogluonModels\\ag-20230701_053244\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230701_053244\\\"\n",
      "AutoGluon Version:  0.8.0\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19041\n",
      "Disk Space Avail:   188.75 GB / 462.26 GB (40.8%)\n",
      "Train Data Rows:    26656\n",
      "Train Data Columns: 51\n",
      "Label Column: TU13\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9660.21 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.25s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.78s of the 299.74s of remaining time.\n",
      "\t-0.1232\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t1.73s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 197.77s of the 297.74s of remaining time.\n",
      "\t-0.1104\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t1.71s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 195.89s of the 295.85s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.1669\t = Validation score   (-mean_absolute_error)\n",
      "\t136.09s\t = Training   runtime\n",
      "\t125.67s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 35.47s of the 135.43s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.1183\t = Validation score   (-mean_absolute_error)\n",
      "\t11.09s\t = Training   runtime\n",
      "\t0.56s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 17.79s of the 117.75s of remaining time.\n",
      "\t-0.1064\t = Validation score   (-mean_absolute_error)\n",
      "\t23.79s\t = Training   runtime\n",
      "\t0.86s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.74s of the 92.92s of remaining time.\n",
      "\t-0.102\t = Validation score   (-mean_absolute_error)\n",
      "\t0.38s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 92.52s of the 92.51s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.1689\t = Validation score   (-mean_absolute_error)\n",
      "\t80.3s\t = Training   runtime\n",
      "\t85.94s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.75s of the -6.68s of remaining time.\n",
      "\t-0.1689\t = Validation score   (-mean_absolute_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 306.72s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230701_053244\\\")\n",
      " 38%|███▊      | 13/34 [1:15:18<1:55:52, 331.07s/it]No path specified. Models will be saved in: \"AutogluonModels\\ag-20230701_053752\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230701_053752\\\"\n",
      "AutoGluon Version:  0.8.0\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19041\n",
      "Disk Space Avail:   188.31 GB / 462.26 GB (40.7%)\n",
      "Train Data Rows:    26656\n",
      "Train Data Columns: 51\n",
      "Label Column: TU14\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9528.22 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.26s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.78s of the 299.73s of remaining time.\n",
      "\t-0.1804\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.63s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 197.99s of the 297.95s of remaining time.\n",
      "\t-0.1673\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t1.7s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 196.13s of the 296.09s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.2153\t = Validation score   (-mean_absolute_error)\n",
      "\t122.9s\t = Training   runtime\n",
      "\t101.92s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 51.96s of the 151.92s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.1548\t = Validation score   (-mean_absolute_error)\n",
      "\t7.28s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 38.46s of the 138.41s of remaining time.\n",
      "\t-0.1609\t = Validation score   (-mean_absolute_error)\n",
      "\t31.35s\t = Training   runtime\n",
      "\t0.98s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 5.93s of the 105.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-3.5435\t = Validation score   (-mean_absolute_error)\n",
      "\t7.02s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.74s of the 92.71s of remaining time.\n",
      "\t-0.1495\t = Validation score   (-mean_absolute_error)\n",
      "\t0.44s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 92.22s of the 92.2s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.2191\t = Validation score   (-mean_absolute_error)\n",
      "\t78.68s\t = Training   runtime\n",
      "\t83.99s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.74s of the -6.06s of remaining time.\n",
      "\t-0.2191\t = Validation score   (-mean_absolute_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 306.15s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230701_053752\\\")\n",
      " 41%|████      | 14/34 [1:20:51<1:50:35, 331.77s/it]No path specified. Models will be saved in: \"AutogluonModels\\ag-20230701_054326\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230701_054326\\\"\n",
      "AutoGluon Version:  0.8.0\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19041\n",
      "Disk Space Avail:   187.87 GB / 462.26 GB (40.6%)\n",
      "Train Data Rows:    26656\n",
      "Train Data Columns: 51\n",
      "Label Column: TU15\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9587.17 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.26s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.78s of the 299.74s of remaining time.\n",
      "\t-0.2952\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.65s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 197.99s of the 297.95s of remaining time.\n",
      "\t-0.2824\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t1.7s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 196.12s of the 296.08s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.3178\t = Validation score   (-mean_absolute_error)\n",
      "\t109.9s\t = Training   runtime\n",
      "\t41.95s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 72.33s of the 172.29s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.2485\t = Validation score   (-mean_absolute_error)\n",
      "\t7.45s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 58.84s of the 158.8s of remaining time.\n",
      "\t-0.2701\t = Validation score   (-mean_absolute_error)\n",
      "\t40.0s\t = Training   runtime\n",
      "\t1.07s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 17.48s of the 117.44s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.5594\t = Validation score   (-mean_absolute_error)\n",
      "\t16.47s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.74s of the 95.01s of remaining time.\n",
      "\t-0.2443\t = Validation score   (-mean_absolute_error)\n",
      "\t0.45s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 94.53s of the 94.52s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.3141\t = Validation score   (-mean_absolute_error)\n",
      "\t80.51s\t = Training   runtime\n",
      "\t53.54s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.74s of the -0.87s of remaining time.\n",
      "\t-0.3141\t = Validation score   (-mean_absolute_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 300.92s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230701_054326\\\")\n",
      " 44%|████▍     | 15/34 [1:26:10<1:43:49, 327.86s/it]No path specified. Models will be saved in: \"AutogluonModels\\ag-20230701_054845\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230701_054845\\\"\n",
      "AutoGluon Version:  0.8.0\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19041\n",
      "Disk Space Avail:   187.48 GB / 462.26 GB (40.6%)\n",
      "Train Data Rows:    26656\n",
      "Train Data Columns: 51\n",
      "Label Column: TU16\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9615.56 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.24s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.79s of the 299.75s of remaining time.\n",
      "\t-0.37\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t1.68s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 197.96s of the 297.92s of remaining time.\n",
      "\t-0.3579\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t1.7s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 196.08s of the 296.05s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.3922\t = Validation score   (-mean_absolute_error)\n",
      "\t81.2s\t = Training   runtime\n",
      "\t34.75s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 104.52s of the 204.48s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.3281\t = Validation score   (-mean_absolute_error)\n",
      "\t6.9s\t = Training   runtime\n",
      "\t0.43s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 91.65s of the 191.61s of remaining time.\n",
      "\t-0.3437\t = Validation score   (-mean_absolute_error)\n",
      "\t41.82s\t = Training   runtime\n",
      "\t1.1s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 48.39s of the 148.36s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.4557\t = Validation score   (-mean_absolute_error)\n",
      "\t41.0s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 1.3s of the 101.27s of remaining time.\n",
      "\t-0.3308\t = Validation score   (-mean_absolute_error)\n",
      "\t8.45s\t = Training   runtime\n",
      "\t1.12s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.76s of the 91.37s of remaining time.\n",
      "\t-0.319\t = Validation score   (-mean_absolute_error)\n",
      "\t0.46s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 90.87s of the 90.86s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.3885\t = Validation score   (-mean_absolute_error)\n",
      "\t77.67s\t = Training   runtime\n",
      "\t47.36s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.76s of the -0.47s of remaining time.\n",
      "\t-0.3885\t = Validation score   (-mean_absolute_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 300.51s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230701_054845\\\")\n",
      " 47%|████▋     | 16/34 [1:31:23<1:37:03, 323.53s/it]No path specified. Models will be saved in: \"AutogluonModels\\ag-20230701_055358\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230701_055358\\\"\n",
      "AutoGluon Version:  0.8.0\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19041\n",
      "Disk Space Avail:   186.93 GB / 462.26 GB (40.4%)\n",
      "Train Data Rows:    26656\n",
      "Train Data Columns: 51\n",
      "Label Column: TU17\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9567.59 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.24s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.79s of the 299.76s of remaining time.\n",
      "\t-1.0994\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t1.61s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 198.03s of the 298.0s of remaining time.\n",
      "\t-1.0832\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t1.62s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 196.25s of the 296.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-1.1561\t = Validation score   (-mean_absolute_error)\n",
      "\t63.66s\t = Training   runtime\n",
      "\t16.22s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 123.24s of the 223.2s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-1.0569\t = Validation score   (-mean_absolute_error)\n",
      "\t8.28s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 108.96s of the 208.93s of remaining time.\n",
      "\t-1.0062\t = Validation score   (-mean_absolute_error)\n",
      "\t59.17s\t = Training   runtime\n",
      "\t1.27s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 48.13s of the 148.1s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-1.1759\t = Validation score   (-mean_absolute_error)\n",
      "\t40.59s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 1.65s of the 101.61s of remaining time.\n",
      "\t-1.0013\t = Validation score   (-mean_absolute_error)\n",
      "\t11.16s\t = Training   runtime\n",
      "\t1.22s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.76s of the 88.82s of remaining time.\n",
      "\t-0.9889\t = Validation score   (-mean_absolute_error)\n",
      "\t0.46s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 88.34s of the 88.33s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-1.0427\t = Validation score   (-mean_absolute_error)\n",
      "\t33.63s\t = Training   runtime\n",
      "\t4.7s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 47.44s of the 47.43s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.9796\t = Validation score   (-mean_absolute_error)\n",
      "\t7.57s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 33.89s of the 33.87s of remaining time.\n",
      "\t-0.9768\t = Validation score   (-mean_absolute_error)\n",
      "\t115.26s\t = Training   runtime\n",
      "\t1.56s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.76s of the -83.37s of remaining time.\n",
      "\t-0.9588\t = Validation score   (-mean_absolute_error)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 383.68s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230701_055358\\\")\n",
      " 50%|█████     | 17/34 [1:38:01<1:37:59, 345.88s/it]No path specified. Models will be saved in: \"AutogluonModels\\ag-20230701_060036\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230701_060036\\\"\n",
      "AutoGluon Version:  0.8.0\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19041\n",
      "Disk Space Avail:   186.03 GB / 462.26 GB (40.2%)\n",
      "Train Data Rows:    26656\n",
      "Train Data Columns: 51\n",
      "Label Column: TD1\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9556.6 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.24s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.79s of the 299.76s of remaining time.\n",
      "\t-5.5672\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.61s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 198.04s of the 298.01s of remaining time.\n",
      "\t-5.4285\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.64s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 196.24s of the 296.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-5.1298\t = Validation score   (-mean_absolute_error)\n",
      "\t136.3s\t = Training   runtime\n",
      "\t119.57s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 35.62s of the 135.59s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-4.9326\t = Validation score   (-mean_absolute_error)\n",
      "\t32.69s\t = Training   runtime\n",
      "\t20.53s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.76s of the 94.7s of remaining time.\n",
      "\t-4.8057\t = Validation score   (-mean_absolute_error)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 94.34s of the 94.33s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-4.1956\t = Validation score   (-mean_absolute_error)\n",
      "\t15.06s\t = Training   runtime\n",
      "\t1.48s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 72.45s of the 72.43s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-4.2327\t = Validation score   (-mean_absolute_error)\n",
      "\t9.47s\t = Training   runtime\n",
      "\t0.48s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 56.6s of the 56.59s of remaining time.\n",
      "\t-4.001\t = Validation score   (-mean_absolute_error)\n",
      "\t83.13s\t = Training   runtime\n",
      "\t1.52s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.76s of the -28.56s of remaining time.\n",
      "\t-3.996\t = Validation score   (-mean_absolute_error)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 328.92s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230701_060036\\\")\n",
      " 53%|█████▎    | 18/34 [1:44:05<1:33:40, 351.26s/it]No path specified. Models will be saved in: \"AutogluonModels\\ag-20230701_060640\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230701_060640\\\"\n",
      "AutoGluon Version:  0.8.0\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19041\n",
      "Disk Space Avail:   185.35 GB / 462.26 GB (40.1%)\n",
      "Train Data Rows:    26656\n",
      "Train Data Columns: 51\n",
      "Label Column: TD2\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9552.52 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.29s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.76s of the 299.71s of remaining time.\n",
      "\t-2.3866\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.71s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 197.89s of the 297.84s of remaining time.\n",
      "\t-2.3141\t = Validation score   (-mean_absolute_error)\n",
      "\t0.06s\t = Training   runtime\n",
      "\t1.66s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 196.06s of the 296.01s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-2.2106\t = Validation score   (-mean_absolute_error)\n",
      "\t133.18s\t = Training   runtime\n",
      "\t72.53s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 44.3s of the 144.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-2.1522\t = Validation score   (-mean_absolute_error)\n",
      "\t17.43s\t = Training   runtime\n",
      "\t1.8s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 20.02s of the 119.98s of remaining time.\n",
      "\t-1.967\t = Validation score   (-mean_absolute_error)\n",
      "\t64.6s\t = Training   runtime\n",
      "\t1.35s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.71s of the 53.61s of remaining time.\n",
      "\t-1.9448\t = Validation score   (-mean_absolute_error)\n",
      "\t0.38s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 53.18s of the 53.16s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-1.81\t = Validation score   (-mean_absolute_error)\n",
      "\t20.29s\t = Training   runtime\n",
      "\t1.83s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 25.91s of the 25.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-1.7534\t = Validation score   (-mean_absolute_error)\n",
      "\t6.52s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 13.37s of the 13.36s of remaining time.\n",
      "\t-1.7147\t = Validation score   (-mean_absolute_error)\n",
      "\t102.99s\t = Training   runtime\n",
      "\t1.59s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.71s of the -91.69s of remaining time.\n",
      "\t-1.6964\t = Validation score   (-mean_absolute_error)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 392.01s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230701_060640\\\")\n",
      " 56%|█████▌    | 19/34 [1:51:04<1:32:53, 371.58s/it]No path specified. Models will be saved in: \"AutogluonModels\\ag-20230701_061339\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230701_061339\\\"\n",
      "AutoGluon Version:  0.8.0\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19041\n",
      "Disk Space Avail:   184.57 GB / 462.26 GB (39.9%)\n",
      "Train Data Rows:    26656\n",
      "Train Data Columns: 51\n",
      "Label Column: TD3\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9518.72 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.25s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.78s of the 299.74s of remaining time.\n",
      "\t-0.9738\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.64s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 197.98s of the 297.94s of remaining time.\n",
      "\t-0.946\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.63s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 196.19s of the 296.15s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.8859\t = Validation score   (-mean_absolute_error)\n",
      "\t62.19s\t = Training   runtime\n",
      "\t26.58s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 124.56s of the 224.52s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.835\t = Validation score   (-mean_absolute_error)\n",
      "\t8.29s\t = Training   runtime\n",
      "\t0.74s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 110.05s of the 210.01s of remaining time.\n",
      "\t-0.825\t = Validation score   (-mean_absolute_error)\n",
      "\t75.49s\t = Training   runtime\n",
      "\t1.31s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 32.63s of the 132.59s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-1.0276\t = Validation score   (-mean_absolute_error)\n",
      "\t28.09s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.74s of the 98.42s of remaining time.\n",
      "\t-0.7999\t = Validation score   (-mean_absolute_error)\n",
      "\t0.42s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 97.98s of the 97.97s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.7674\t = Validation score   (-mean_absolute_error)\n",
      "\t15.19s\t = Training   runtime\n",
      "\t1.71s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 76.3s of the 76.29s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.7319\t = Validation score   (-mean_absolute_error)\n",
      "\t5.71s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 64.54s of the 64.53s of remaining time.\n",
      "\t-0.7453\t = Validation score   (-mean_absolute_error)\n",
      "\t104.23s\t = Training   runtime\n",
      "\t1.51s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.75s of the -41.58s of remaining time.\n",
      "\t-0.7187\t = Validation score   (-mean_absolute_error)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 341.89s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230701_061339\\\")\n",
      " 59%|█████▉    | 20/34 [1:56:58<1:25:30, 366.44s/it]No path specified. Models will be saved in: \"AutogluonModels\\ag-20230701_061933\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230701_061933\\\"\n",
      "AutoGluon Version:  0.8.0\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19041\n",
      "Disk Space Avail:   184.07 GB / 462.26 GB (39.8%)\n",
      "Train Data Rows:    26656\n",
      "Train Data Columns: 51\n",
      "Label Column: TD4\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9460.88 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.27s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.77s of the 299.72s of remaining time.\n",
      "\t-0.3872\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.69s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 197.9s of the 297.85s of remaining time.\n",
      "\t-0.3818\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.63s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 196.13s of the 296.09s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.3298\t = Validation score   (-mean_absolute_error)\n",
      "\t10.33s\t = Training   runtime\n",
      "\t1.63s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 179.48s of the 279.43s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.31\t = Validation score   (-mean_absolute_error)\n",
      "\t6.4s\t = Training   runtime\n",
      "\t0.42s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 166.56s of the 266.51s of remaining time.\n",
      "\t-0.3549\t = Validation score   (-mean_absolute_error)\n",
      "\t81.47s\t = Training   runtime\n",
      "\t1.32s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 83.49s of the 183.45s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.3384\t = Validation score   (-mean_absolute_error)\n",
      "\t67.11s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 10.49s of the 110.45s of remaining time.\n",
      "\t-0.3481\t = Validation score   (-mean_absolute_error)\n",
      "\t12.1s\t = Training   runtime\n",
      "\t1.2s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.73s of the 96.82s of remaining time.\n",
      "\t-0.3047\t = Validation score   (-mean_absolute_error)\n",
      "\t0.49s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 96.31s of the 96.3s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.3446\t = Validation score   (-mean_absolute_error)\n",
      "\t9.0s\t = Training   runtime\n",
      "\t0.72s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 81.01s of the 81.0s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.3219\t = Validation score   (-mean_absolute_error)\n",
      "\t7.44s\t = Training   runtime\n",
      "\t0.42s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 67.46s of the 67.45s of remaining time.\n",
      "\t-0.3373\t = Validation score   (-mean_absolute_error)\n",
      "\t126.99s\t = Training   runtime\n",
      "\t1.58s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.73s of the -61.51s of remaining time.\n",
      "\t-0.3155\t = Validation score   (-mean_absolute_error)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 361.83s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230701_061933\\\")\n",
      " 62%|██████▏   | 21/34 [2:03:03<1:19:15, 365.80s/it]No path specified. Models will be saved in: \"AutogluonModels\\ag-20230701_062537\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230701_062537\\\"\n",
      "AutoGluon Version:  0.8.0\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19041\n",
      "Disk Space Avail:   183.56 GB / 462.26 GB (39.7%)\n",
      "Train Data Rows:    26656\n",
      "Train Data Columns: 51\n",
      "Label Column: TD5\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9421.29 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.26s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.77s of the 299.73s of remaining time.\n",
      "\t-1.9067\t = Validation score   (-mean_absolute_error)\n",
      "\t0.06s\t = Training   runtime\n",
      "\t1.66s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 197.91s of the 297.86s of remaining time.\n",
      "\t-1.8529\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.71s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 195.95s of the 295.91s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-1.8228\t = Validation score   (-mean_absolute_error)\n",
      "\t145.33s\t = Training   runtime\n",
      "\t116.88s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 27.83s of the 127.78s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-1.6534\t = Validation score   (-mean_absolute_error)\n",
      "\t25.55s\t = Training   runtime\n",
      "\t14.37s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.74s of the 94.84s of remaining time.\n",
      "\t-1.6176\t = Validation score   (-mean_absolute_error)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 94.42s of the 94.4s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-1.4306\t = Validation score   (-mean_absolute_error)\n",
      "\t21.36s\t = Training   runtime\n",
      "\t2.44s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 66.16s of the 66.14s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-1.3878\t = Validation score   (-mean_absolute_error)\n",
      "\t7.4s\t = Training   runtime\n",
      "\t0.42s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 52.59s of the 52.57s of remaining time.\n",
      "\t-1.331\t = Validation score   (-mean_absolute_error)\n",
      "\t85.74s\t = Training   runtime\n",
      "\t1.41s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.74s of the -34.94s of remaining time.\n",
      "\t-1.3203\t = Validation score   (-mean_absolute_error)\n",
      "\t0.32s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 335.35s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230701_062537\\\")\n",
      " 65%|██████▍   | 22/34 [2:09:11<1:13:20, 366.71s/it]No path specified. Models will be saved in: \"AutogluonModels\\ag-20230701_063146\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230701_063146\\\"\n",
      "AutoGluon Version:  0.8.0\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19041\n",
      "Disk Space Avail:   183.06 GB / 462.26 GB (39.6%)\n",
      "Train Data Rows:    26656\n",
      "Train Data Columns: 51\n",
      "Label Column: TD6\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9533.22 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.27s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.77s of the 299.72s of remaining time.\n",
      "\t-0.9079\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.66s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 197.99s of the 297.94s of remaining time.\n",
      "\t-0.8836\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t1.66s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 196.14s of the 296.09s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.9255\t = Validation score   (-mean_absolute_error)\n",
      "\t141.98s\t = Training   runtime\n",
      "\t103.03s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 31.39s of the 131.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.8351\t = Validation score   (-mean_absolute_error)\n",
      "\t24.61s\t = Training   runtime\n",
      "\t2.88s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.73s of the 99.79s of remaining time.\n",
      "\t-0.8022\t = Validation score   (-mean_absolute_error)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 99.42s of the 99.4s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.7772\t = Validation score   (-mean_absolute_error)\n",
      "\t30.49s\t = Training   runtime\n",
      "\t4.22s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 62.05s of the 62.04s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.7306\t = Validation score   (-mean_absolute_error)\n",
      "\t6.58s\t = Training   runtime\n",
      "\t0.43s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 49.41s of the 49.4s of remaining time.\n",
      "\t-0.7018\t = Validation score   (-mean_absolute_error)\n",
      "\t85.34s\t = Training   runtime\n",
      "\t1.42s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.73s of the -37.68s of remaining time.\n",
      "\t-0.6935\t = Validation score   (-mean_absolute_error)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 337.99s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230701_063146\\\")\n",
      " 68%|██████▊   | 23/34 [2:15:22<1:07:25, 367.79s/it]No path specified. Models will be saved in: \"AutogluonModels\\ag-20230701_063757\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230701_063757\\\"\n",
      "AutoGluon Version:  0.8.0\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19041\n",
      "Disk Space Avail:   182.61 GB / 462.26 GB (39.5%)\n",
      "Train Data Rows:    26656\n",
      "Train Data Columns: 51\n",
      "Label Column: TD7\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9495.83 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.27s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.77s of the 299.73s of remaining time.\n",
      "\t-0.311\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.73s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 197.91s of the 297.86s of remaining time.\n",
      "\t-0.2979\t = Validation score   (-mean_absolute_error)\n",
      "\t0.06s\t = Training   runtime\n",
      "\t1.71s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 196.0s of the 295.96s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.3567\t = Validation score   (-mean_absolute_error)\n",
      "\t76.8s\t = Training   runtime\n",
      "\t20.94s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 109.36s of the 209.32s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.2881\t = Validation score   (-mean_absolute_error)\n",
      "\t7.4s\t = Training   runtime\n",
      "\t0.47s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 95.83s of the 195.79s of remaining time.\n",
      "\t-0.2859\t = Validation score   (-mean_absolute_error)\n",
      "\t42.48s\t = Training   runtime\n",
      "\t1.04s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 52.08s of the 152.04s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.4413\t = Validation score   (-mean_absolute_error)\n",
      "\t41.92s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 4.05s of the 104.01s of remaining time.\n",
      "\t-0.274\t = Validation score   (-mean_absolute_error)\n",
      "\t8.21s\t = Training   runtime\n",
      "\t1.05s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.73s of the 94.45s of remaining time.\n",
      "\t-0.2675\t = Validation score   (-mean_absolute_error)\n",
      "\t0.48s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 93.94s of the 93.93s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.3334\t = Validation score   (-mean_absolute_error)\n",
      "\t41.05s\t = Training   runtime\n",
      "\t7.13s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 45.36s of the 45.34s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.2719\t = Validation score   (-mean_absolute_error)\n",
      "\t6.97s\t = Training   runtime\n",
      "\t0.47s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 32.37s of the 32.35s of remaining time.\n",
      "\t-0.2666\t = Validation score   (-mean_absolute_error)\n",
      "\t71.58s\t = Training   runtime\n",
      "\t1.26s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.73s of the -40.78s of remaining time.\n",
      "\t-0.2591\t = Validation score   (-mean_absolute_error)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 341.13s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230701_063757\\\")\n",
      " 71%|███████   | 24/34 [2:21:19<1:00:47, 364.72s/it]No path specified. Models will be saved in: \"AutogluonModels\\ag-20230701_064354\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230701_064354\\\"\n",
      "AutoGluon Version:  0.8.0\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19041\n",
      "Disk Space Avail:   182.14 GB / 462.26 GB (39.4%)\n",
      "Train Data Rows:    26656\n",
      "Train Data Columns: 51\n",
      "Label Column: TD8\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9534.91 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.25s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.78s of the 299.74s of remaining time.\n",
      "\t-0.085\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t1.66s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 197.94s of the 297.91s of remaining time.\n",
      "\t-0.0743\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.63s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 196.15s of the 296.11s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.1263\t = Validation score   (-mean_absolute_error)\n",
      "\t134.49s\t = Training   runtime\n",
      "\t110.96s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 38.71s of the 138.67s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.0612\t = Validation score   (-mean_absolute_error)\n",
      "\t7.67s\t = Training   runtime\n",
      "\t0.43s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 24.86s of the 124.83s of remaining time.\n",
      "\t-0.0695\t = Validation score   (-mean_absolute_error)\n",
      "\t29.2s\t = Training   runtime\n",
      "\t0.92s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.75s of the 94.52s of remaining time.\n",
      "\t-0.0597\t = Validation score   (-mean_absolute_error)\n",
      "\t0.38s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 94.12s of the 94.11s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.1246\t = Validation score   (-mean_absolute_error)\n",
      "\t81.17s\t = Training   runtime\n",
      "\t81.64s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.75s of the -5.56s of remaining time.\n",
      "\t-0.1246\t = Validation score   (-mean_absolute_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 305.73s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230701_064354\\\")\n",
      " 74%|███████▎  | 25/34 [2:26:55<53:24, 356.10s/it]  No path specified. Models will be saved in: \"AutogluonModels\\ag-20230701_064930\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230701_064930\\\"\n",
      "AutoGluon Version:  0.8.0\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19041\n",
      "Disk Space Avail:   181.70 GB / 462.26 GB (39.3%)\n",
      "Train Data Rows:    26656\n",
      "Train Data Columns: 51\n",
      "Label Column: TD9\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9536.38 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.24s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.79s of the 299.76s of remaining time.\n",
      "\t-2.3975\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.72s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 197.93s of the 297.9s of remaining time.\n",
      "\t-2.3994\t = Validation score   (-mean_absolute_error)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t1.66s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 196.04s of the 296.01s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-3.7227\t = Validation score   (-mean_absolute_error)\n",
      "\t56.96s\t = Training   runtime\n",
      "\t5.25s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 126.02s of the 225.98s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-5.5154\t = Validation score   (-mean_absolute_error)\n",
      "\t6.08s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 113.28s of the 213.25s of remaining time.\n",
      "\t-3.5018\t = Validation score   (-mean_absolute_error)\n",
      "\t31.83s\t = Training   runtime\n",
      "\t1.04s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 80.21s of the 180.18s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-4.161\t = Validation score   (-mean_absolute_error)\n",
      "\t64.87s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 8.65s of the 108.62s of remaining time.\n",
      "\t-3.2787\t = Validation score   (-mean_absolute_error)\n",
      "\t5.99s\t = Training   runtime\n",
      "\t1.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1.37s of the 101.34s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping NeuralNetFastAI_BAG_L1.\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.76s of the 87.89s of remaining time.\n",
      "2023-07-01 14:53:03,030\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-07-01 14:53:03,036\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-07-01 14:53:03,041\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-07-01 14:53:03,044\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-07-01 14:53:03,048\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-07-01 14:53:03,052\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-07-01 14:53:03,057\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-2.3975\t = Validation score   (-mean_absolute_error)\n",
      "\t0.79s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 87.05s of the 87.04s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-4.0156\t = Validation score   (-mean_absolute_error)\n",
      "\t53.18s\t = Training   runtime\n",
      "\t3.37s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 22.41s of the 22.4s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-4.9547\t = Validation score   (-mean_absolute_error)\n",
      "\t7.32s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 8.77s of the 8.75s of remaining time.\n",
      "\t-4.1287\t = Validation score   (-mean_absolute_error)\n",
      "\t44.09s\t = Training   runtime\n",
      "\t1.15s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.76s of the -36.71s of remaining time.\n",
      "\t-3.9843\t = Validation score   (-mean_absolute_error)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 337.08s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230701_064930\\\")\n",
      " 76%|███████▋  | 26/34 [2:32:33<46:45, 350.66s/it]No path specified. Models will be saved in: \"AutogluonModels\\ag-20230701_065508\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230701_065508\\\"\n",
      "AutoGluon Version:  0.8.0\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19041\n",
      "Disk Space Avail:   181.43 GB / 462.26 GB (39.2%)\n",
      "Train Data Rows:    26656\n",
      "Train Data Columns: 51\n",
      "Label Column: TD10\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9483.68 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.28s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.76s of the 299.71s of remaining time.\n",
      "\t-0.0819\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t1.69s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 197.9s of the 297.85s of remaining time.\n",
      "\t-0.0708\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t1.75s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 195.93s of the 295.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.1177\t = Validation score   (-mean_absolute_error)\n",
      "\t129.81s\t = Training   runtime\n",
      "\t130.17s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 40.93s of the 140.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.0617\t = Validation score   (-mean_absolute_error)\n",
      "\t8.4s\t = Training   runtime\n",
      "\t0.53s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 25.32s of the 125.27s of remaining time.\n",
      "\t-0.0659\t = Validation score   (-mean_absolute_error)\n",
      "\t26.65s\t = Training   runtime\n",
      "\t0.97s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.72s of the 97.47s of remaining time.\n",
      "\t-0.059\t = Validation score   (-mean_absolute_error)\n",
      "\t0.42s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 97.03s of the 97.02s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.1182\t = Validation score   (-mean_absolute_error)\n",
      "\t82.65s\t = Training   runtime\n",
      "\t83.89s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.72s of the -6.12s of remaining time.\n",
      "\t-0.1182\t = Validation score   (-mean_absolute_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 306.2s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230701_065508\\\")\n",
      " 79%|███████▉  | 27/34 [2:38:11<40:27, 346.83s/it]No path specified. Models will be saved in: \"AutogluonModels\\ag-20230701_070046\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230701_070046\\\"\n",
      "AutoGluon Version:  0.8.0\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19041\n",
      "Disk Space Avail:   180.98 GB / 462.26 GB (39.2%)\n",
      "Train Data Rows:    26656\n",
      "Train Data Columns: 51\n",
      "Label Column: TD11\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9522.82 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\t0.3s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.29s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.76s of the 299.7s of remaining time.\n",
      "\t-0.1231\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t1.77s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 197.82s of the 297.76s of remaining time.\n",
      "\t-0.1125\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t1.83s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 195.74s of the 295.69s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.1535\t = Validation score   (-mean_absolute_error)\n",
      "\t139.61s\t = Training   runtime\n",
      "\t79.75s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 34.39s of the 134.34s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.0994\t = Validation score   (-mean_absolute_error)\n",
      "\t7.83s\t = Training   runtime\n",
      "\t0.49s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 19.59s of the 119.54s of remaining time.\n",
      "\t-0.1043\t = Validation score   (-mean_absolute_error)\n",
      "\t31.63s\t = Training   runtime\n",
      "\t0.99s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.71s of the 86.75s of remaining time.\n",
      "\t-0.0954\t = Validation score   (-mean_absolute_error)\n",
      "\t0.48s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 86.25s of the 86.24s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.1508\t = Validation score   (-mean_absolute_error)\n",
      "\t75.91s\t = Training   runtime\n",
      "\t74.04s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.71s of the -7.16s of remaining time.\n",
      "\t-0.1508\t = Validation score   (-mean_absolute_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 307.2s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230701_070046\\\")\n",
      " 82%|████████▏ | 28/34 [2:43:45<34:16, 342.82s/it]No path specified. Models will be saved in: \"AutogluonModels\\ag-20230701_070619\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230701_070619\\\"\n",
      "AutoGluon Version:  0.8.0\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19041\n",
      "Disk Space Avail:   180.58 GB / 462.26 GB (39.1%)\n",
      "Train Data Rows:    26656\n",
      "Train Data Columns: 51\n",
      "Label Column: TD12\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9603.75 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\t0.3s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.29s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.76s of the 299.71s of remaining time.\n",
      "\t-0.1366\t = Validation score   (-mean_absolute_error)\n",
      "\t0.06s\t = Training   runtime\n",
      "\t1.81s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 197.8s of the 297.75s of remaining time.\n",
      "\t-0.1255\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t1.79s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 195.83s of the 295.78s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.1653\t = Validation score   (-mean_absolute_error)\n",
      "\t135.86s\t = Training   runtime\n",
      "\t73.27s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 42.03s of the 141.98s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.1113\t = Validation score   (-mean_absolute_error)\n",
      "\t8.87s\t = Training   runtime\n",
      "\t0.48s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 26.08s of the 126.03s of remaining time.\n",
      "\t-0.1183\t = Validation score   (-mean_absolute_error)\n",
      "\t33.63s\t = Training   runtime\n",
      "\t1.03s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.71s of the 91.18s of remaining time.\n",
      "\t-0.1068\t = Validation score   (-mean_absolute_error)\n",
      "\t0.45s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 90.71s of the 90.7s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.1651\t = Validation score   (-mean_absolute_error)\n",
      "\t77.42s\t = Training   runtime\n",
      "\t79.14s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.71s of the -6.79s of remaining time.\n",
      "\t-0.1651\t = Validation score   (-mean_absolute_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 306.84s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230701_070619\\\")\n",
      " 85%|████████▌ | 29/34 [2:49:18<28:20, 340.01s/it]No path specified. Models will be saved in: \"AutogluonModels\\ag-20230701_071153\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230701_071153\\\"\n",
      "AutoGluon Version:  0.8.0\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19041\n",
      "Disk Space Avail:   180.17 GB / 462.26 GB (39.0%)\n",
      "Train Data Rows:    26656\n",
      "Train Data Columns: 51\n",
      "Label Column: TD13\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9604.18 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\t0.3s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.31s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.74s of the 299.69s of remaining time.\n",
      "\t-0.1142\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.79s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 197.81s of the 297.75s of remaining time.\n",
      "\t-0.102\t = Validation score   (-mean_absolute_error)\n",
      "\t0.06s\t = Training   runtime\n",
      "\t1.75s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 195.87s of the 295.81s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.1478\t = Validation score   (-mean_absolute_error)\n",
      "\t140.69s\t = Training   runtime\n",
      "\t94.14s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 32.74s of the 132.69s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.0949\t = Validation score   (-mean_absolute_error)\n",
      "\t8.25s\t = Training   runtime\n",
      "\t0.46s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 17.36s of the 117.3s of remaining time.\n",
      "\t-0.1031\t = Validation score   (-mean_absolute_error)\n",
      "\t31.48s\t = Training   runtime\n",
      "\t1.01s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.69s of the 84.53s of remaining time.\n",
      "\t-0.0908\t = Validation score   (-mean_absolute_error)\n",
      "\t0.42s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 84.09s of the 84.08s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.1504\t = Validation score   (-mean_absolute_error)\n",
      "\t73.72s\t = Training   runtime\n",
      "\t69.86s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.69s of the -6.69s of remaining time.\n",
      "\t-0.1504\t = Validation score   (-mean_absolute_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 306.76s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230701_071153\\\")\n",
      " 88%|████████▊ | 30/34 [2:54:55<22:36, 339.12s/it]No path specified. Models will be saved in: \"AutogluonModels\\ag-20230701_071730\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230701_071730\\\"\n",
      "AutoGluon Version:  0.8.0\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19041\n",
      "Disk Space Avail:   179.76 GB / 462.26 GB (38.9%)\n",
      "Train Data Rows:    26656\n",
      "Train Data Columns: 51\n",
      "Label Column: TD14\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9670.59 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\t0.3s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.3s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.75s of the 299.7s of remaining time.\n",
      "\t-0.1224\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t1.85s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 197.72s of the 297.67s of remaining time.\n",
      "\t-0.1101\t = Validation score   (-mean_absolute_error)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t1.74s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 195.78s of the 295.72s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.1613\t = Validation score   (-mean_absolute_error)\n",
      "\t139.44s\t = Training   runtime\n",
      "\t114.45s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 31.34s of the 131.28s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.0988\t = Validation score   (-mean_absolute_error)\n",
      "\t8.25s\t = Training   runtime\n",
      "\t0.44s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 15.99s of the 115.94s of remaining time.\n",
      "\t-0.1073\t = Validation score   (-mean_absolute_error)\n",
      "\t32.73s\t = Training   runtime\n",
      "\t1.07s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.7s of the 81.91s of remaining time.\n",
      "\t-0.0954\t = Validation score   (-mean_absolute_error)\n",
      "\t0.42s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 81.47s of the 81.45s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.1586\t = Validation score   (-mean_absolute_error)\n",
      "\t70.99s\t = Training   runtime\n",
      "\t76.06s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.7s of the -7.53s of remaining time.\n",
      "\t-0.1586\t = Validation score   (-mean_absolute_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 307.58s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230701_071730\\\")\n",
      " 91%|█████████ | 31/34 [3:00:33<16:56, 338.83s/it]No path specified. Models will be saved in: \"AutogluonModels\\ag-20230701_072308\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230701_072308\\\"\n",
      "AutoGluon Version:  0.8.0\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19041\n",
      "Disk Space Avail:   179.32 GB / 462.26 GB (38.8%)\n",
      "Train Data Rows:    26656\n",
      "Train Data Columns: 51\n",
      "Label Column: TD15\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9618.63 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\t0.3s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.29s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.76s of the 299.7s of remaining time.\n",
      "\t-0.2055\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t1.81s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 197.77s of the 297.72s of remaining time.\n",
      "\t-0.1932\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t1.82s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 195.74s of the 295.69s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.2352\t = Validation score   (-mean_absolute_error)\n",
      "\t99.28s\t = Training   runtime\n",
      "\t56.81s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 84.32s of the 184.27s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.1669\t = Validation score   (-mean_absolute_error)\n",
      "\t6.21s\t = Training   runtime\n",
      "\t0.4s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 71.34s of the 171.29s of remaining time.\n",
      "\t-0.1858\t = Validation score   (-mean_absolute_error)\n",
      "\t36.85s\t = Training   runtime\n",
      "\t1.04s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 33.22s of the 133.17s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.3454\t = Validation score   (-mean_absolute_error)\n",
      "\t29.01s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.71s of the 97.36s of remaining time.\n",
      "\t-0.1646\t = Validation score   (-mean_absolute_error)\n",
      "\t0.46s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 96.88s of the 96.87s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.2361\t = Validation score   (-mean_absolute_error)\n",
      "\t84.51s\t = Training   runtime\n",
      "\t74.3s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.71s of the -5.25s of remaining time.\n",
      "\t-0.2361\t = Validation score   (-mean_absolute_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 305.29s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230701_072308\\\")\n",
      " 94%|█████████▍| 32/34 [3:05:56<11:08, 334.03s/it]No path specified. Models will be saved in: \"AutogluonModels\\ag-20230701_072831\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230701_072831\\\"\n",
      "AutoGluon Version:  0.8.0\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19041\n",
      "Disk Space Avail:   178.95 GB / 462.26 GB (38.7%)\n",
      "Train Data Rows:    26656\n",
      "Train Data Columns: 51\n",
      "Label Column: TD16\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9592.24 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.28s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.76s of the 299.72s of remaining time.\n",
      "\t-0.2628\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t1.74s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 197.87s of the 297.82s of remaining time.\n",
      "\t-0.2503\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t1.71s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 195.96s of the 295.91s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.2901\t = Validation score   (-mean_absolute_error)\n",
      "\t81.27s\t = Training   runtime\n",
      "\t36.03s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 102.34s of the 202.29s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.2236\t = Validation score   (-mean_absolute_error)\n",
      "\t7.01s\t = Training   runtime\n",
      "\t0.45s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 88.64s of the 188.59s of remaining time.\n",
      "\t-0.2411\t = Validation score   (-mean_absolute_error)\n",
      "\t39.84s\t = Training   runtime\n",
      "\t1.1s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 47.42s of the 147.37s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.3476\t = Validation score   (-mean_absolute_error)\n",
      "\t40.68s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 0.01s of the 99.96s of remaining time.\n",
      "\t-0.2286\t = Validation score   (-mean_absolute_error)\n",
      "\t8.04s\t = Training   runtime\n",
      "\t1.15s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.72s of the 90.4s of remaining time.\n",
      "\t-0.2169\t = Validation score   (-mean_absolute_error)\n",
      "\t0.51s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 89.85s of the 89.83s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.2915\t = Validation score   (-mean_absolute_error)\n",
      "\t77.02s\t = Training   runtime\n",
      "\t63.07s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.72s of the -3.99s of remaining time.\n",
      "\t-0.2915\t = Validation score   (-mean_absolute_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 304.05s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230701_072831\\\")\n",
      " 97%|█████████▋| 33/34 [3:11:15<05:29, 329.46s/it]No path specified. Models will be saved in: \"AutogluonModels\\ag-20230701_073350\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230701_073350\\\"\n",
      "AutoGluon Version:  0.8.0\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19041\n",
      "Disk Space Avail:   178.45 GB / 462.26 GB (38.6%)\n",
      "Train Data Rows:    26656\n",
      "Train Data Columns: 51\n",
      "Label Column: TD17\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9649.51 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['V1', 'V2', 'V3', 'V4', 'V5', ...]\n",
      "\t\t('int', [])   : 34 | ['TSU1', 'TSU2', 'TSU3', 'TSU4', 'TSU5', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t51 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.88 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.28s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.76s of the 299.71s of remaining time.\n",
      "\t-0.3205\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.74s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 197.88s of the 297.83s of remaining time.\n",
      "\t-0.3114\t = Validation score   (-mean_absolute_error)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t1.8s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 195.84s of the 295.8s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.3677\t = Validation score   (-mean_absolute_error)\n",
      "\t61.26s\t = Training   runtime\n",
      "\t25.06s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 123.97s of the 223.93s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.2639\t = Validation score   (-mean_absolute_error)\n",
      "\t6.4s\t = Training   runtime\n",
      "\t0.43s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 110.97s of the 210.92s of remaining time.\n",
      "\t-0.2954\t = Validation score   (-mean_absolute_error)\n",
      "\t64.18s\t = Training   runtime\n",
      "\t1.32s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 45.16s of the 145.12s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.3765\t = Validation score   (-mean_absolute_error)\n",
      "\t36.52s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 1.72s of the 101.67s of remaining time.\n",
      "\t-0.2871\t = Validation score   (-mean_absolute_error)\n",
      "\t12.16s\t = Training   runtime\n",
      "\t1.26s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.72s of the 87.85s of remaining time.\n",
      "\t-0.2604\t = Validation score   (-mean_absolute_error)\n",
      "\t0.51s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 87.32s of the 87.31s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.3535\t = Validation score   (-mean_absolute_error)\n",
      "\t47.93s\t = Training   runtime\n",
      "\t9.27s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 30.53s of the 30.51s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.2611\t = Validation score   (-mean_absolute_error)\n",
      "\t7.6s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 16.15s of the 16.13s of remaining time.\n",
      "\t-0.2747\t = Validation score   (-mean_absolute_error)\n",
      "\t102.65s\t = Training   runtime\n",
      "\t1.51s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.72s of the -88.41s of remaining time.\n",
      "\t-0.2571\t = Validation score   (-mean_absolute_error)\n",
      "\t0.31s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 388.79s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230701_073350\\\")\n",
      "100%|██████████| 34/34 [3:18:00<00:00, 349.43s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "time_limit = 5*60\n",
    "from tqdm import tqdm\n",
    "for t in tqdm(label):\n",
    "    \n",
    "    predictor = TabularPredictor(label=t,problem_type='regression',eval_metric='mae').fit(traindata[features+[t]], presets='best_quality',time_limit=time_limit)#,time_limit=time_limit\n",
    "    submit[t] = predictor.predict(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-30T15:54:27.121Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "submit.columns = ['序号','上部温度1', '上部温度2', '上部温度3', '上部温度4', '上部温度5', '上部温度6', '上部温度7',\n",
    "       '上部温度8', '上部温度9', '上部温度10', '上部温度11', '上部温度12', '上部温度13', '上部温度14',\n",
    "       '上部温度15', '上部温度16', '上部温度17', '下部温度1', '下部温度2', '下部温度3', '下部温度4',\n",
    "       '下部温度5', '下部温度6', '下部温度7', '下部温度8', '下部温度9', '下部温度10', '下部温度11',\n",
    "       '下部温度12', '下部温度13', '下部温度14', '下部温度15', '下部温度16', '下部温度17']\n",
    "\n",
    "submit.to_csv('submit.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19992, 85), (6664, 85))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train,df_val = train_test_split(traindata,test_size=0.25,random_state=42)\n",
    "df_train.shape,df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# for t in os.listdir('./AutogluonModels/'):\n",
    "#     pre = TabularPredictor.load('./AutogluonModels/'+t)\n",
    "#     print(pre.label)\n",
    "    # print(pre.evaluate(df_val[features+[pre.label]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "automl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
